#!/usr/bin/env python
"""
    Dario Marasco
    Spring 2017
    Drexel University
"""

import os
import operator
import numpy as np

from sklearn.pipeline import Pipeline
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.feature_extraction.text import TfidfTransformer
from sklearn.model_selection import ShuffleSplit
from sklearn.model_selection import train_test_split
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import LeaveOneOut
from sklearn.naive_bayes import MultinomialNB
from sklearn.linear_model import SGDClassifier
from sklearn import metrics

DATA_SETS_PATH = "./dataset/asm"
TEST_TYPE = "control" # control, stunnix, semantic (currently not working)
TEST_FILE_NAME = "a.s" # a.s, a.packed.s, o3.s, o3.packed.s

#ADDITIONAL_PREDICTION = "./prediction"
TEST_QUESTION = "2_1" # 0_0, 0_1, 1_0, 1_1, 2_0, 2_1

def main():
    print DATA_SETS_PATH, TEST_TYPE, TEST_FILE_NAME, TEST_QUESTION
    categories = {}
    corpus = []
    targets = []

    test_names = []
    test_corpus = []
    test_targets = []
    
    code_path = os.path.join(DATA_SETS_PATH, TEST_TYPE)

    # walk over the directory and  
    ind = -1
    for root, dirs, files in os.walk(code_path):
        for f in files:
            if f.endswith(TEST_FILE_NAME):
                who = root.split("/")[4]
                if not categories.has_key(who):
                    ind += 1;
                    categories[who] = ind
                fn = os.path.join(root, f)
                if root.endswith(TEST_QUESTION):
                    test_targets.append(categories[who])
                    test_names.append(who)
                    with open(fn, 'r') as fasm:
                        test_corpus.append(fasm.read())
                else:
                    targets.append(categories[who])
                    with open(fn, 'r') as fasm:
                        corpus.append(fasm.read())


    # Special vectorizer which tokenizes entire lines
    count_vect = CountVectorizer(token_pattern=r".*\n", ngram_range=(1, 6))

    # Define the pipeline for the flow of data
    clf = Pipeline([('vect', count_vect),
                        ('tfidf', TfidfTransformer()),
                        ('clf', MultinomialNB())])
                        #('clf', SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, n_iter=5, random_state=42))])

    # Partition the data
    #X_train, X_test, y_train, y_test = train_test_split(corpus, targets, test_size=0.1) #, random_state=0)

    # Create and train the classifier with the training data and targets
    #clf = clf.fit(X_train, y_train)
    clf = clf.fit(corpus, targets)
    #print clf.score(X_test, y_test)

    #cv = ShuffleSplit(n_splits=6)#, random_state=0) 
    #scores = cross_val_score(clf, X_test, y_test, cv=cv)
    #print scores
    #print("Accuracy: %0.2f (+/- %0.2f)" % (scores.mean(), scores.std() * 2))

    # if there is an additonal test_corpus to test with, those tests are performed here
    if test_corpus:
        predicted = clf.predict(test_corpus)
        categories_ = {v: k for k, v in categories.iteritems()}
        categories_ordered = [_[0] for _ in sorted(categories.items(), key=operator.itemgetter(1))]

        s = 0.0
        for doc, category in zip(test_names, predicted):
            if doc == categories_[category]:
                s += 1
            print '%r => %s' % (doc, categories_[category])
        print "Average accuracy",  s / len(predicted), "\n"
        print metrics.classification_report(test_targets, predicted, target_names=categories_ordered)

if __name__ == "__main__":
    main()

